# Lucid Vigilance API

A FastAPI service that turns prerecorded cab footage into 30‚Äësecond driver vigilance metrics, classifies the driver (Lucid/Drowsy/Asleep), and exposes heart‚Äërate/HRV vitals derived from that state. This guide is written so new teammates can get productive quickly‚Äîfollow it top to bottom if you are just getting started.

---

## 1. What the service does

1. **Video analytics** ‚Äì Upload a clip plus a timestamp; the service replays the 30 seconds immediately before that timestamp, runs MediaPipe Face Mesh + OpenCV on every frame, and emits the safety metrics you see in the legacy dashboard (PERCLOS, yawns, head pose, quality/fps, etc.).
2. **State classification** ‚Äì Feed any 30‚Äësecond bucket (either from the analytics endpoint or an external source) into `/v1/state`. The rule engine tags the driver as **Lucid**, **Drowsy**, or **Asleep**, calculates a risk score, and stores the result in a short‚Äëterm cache.
3. **Vitals derivation** ‚Äì `/v1/sim/hr`, `/v1/sim/hrv`, and `/v1/sim/vitals` reuse the most recent state to emit realistic heart rate and HRV traces. They respect state confidence, add smooth temporal inertia, and can be made deterministic with a seed if you need repeatable tests.

The entire workflow mirrors what the front‚Äëend tester does automatically:

```
Upload video + timestamp  -->  /api/window
                              ‚îÇ
                              ‚îî> /v1/state (auto-called by tester)
                                    ‚îÇ
                                    ‚îî> /v1/sim/hr*, if vitals needed
```

---

## 2. Quick start

| Step | Command |
|------|---------|
| 1. Clone & enter | `git clone <repo> && cd api2` |
| 2. Create venv | `python3 -m venv .venv && source .venv/bin/activate` |
| 3. Install deps | `pip install -r requirements.txt` |
| 4. Run tests (optional) | `pytest tests/test_state_classifier.py tests/test_sim_vitals.py` |
| 5. Start API | `uvicorn app.main:app --reload --port 8000` |

Open `http://127.0.0.1:8000/docs` for autogenerated OpenAPI docs or load `api_tester.html` in your browser to use the one‚Äëpage manual tester.

> **Tip:** The tester handles the whole pipeline (window ‚Üí state ‚Üí vitals) and shows every raw JSON response, which keeps new devs from needing Postman right away.

---

## 3. Endpoints at a glance

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/window` | `POST (form)` | Uploads a video file + timestamp, returns the 30‚Äësecond bucket metrics. |
| `/v1/state` | `POST (json)` | Classifies a bucket into Lucid/Drowsy/Asleep, returns reasons, risk score, confidence. |
| `/v1/sim/hr` | `POST (json)` | Returns heart rate (bpm) for the current driver state. |
| `/v1/sim/hrv` | `POST (json)` | Returns HRV RMSSD (ms) for the current state. |
| `/v1/sim/vitals` | `POST (json)` | Convenience endpoint returning both HR and HRV together. |

### 3.1 `/api/window`

**Form fields**

| Field | Required | Notes |
|-------|----------|-------|
| `video` | ‚úÖ | Video file (mp4/mov). Only the 30 seconds before the timestamp are analyzed. |
| `timestamp` | ‚úÖ | Seconds or `HH:MM:SS(.mmm)` string locating the end of the 30‚Äësecond window. |
| `session_id` | ‚¨ú | Passed through to responses; useful as your trip key. |
| `driver_id` | ‚¨ú | Passed through for state/vitals caching. |

**Response fields (subset)**

```
{
  "ts_end": "2025-11-08T08:49:16Z",
  "session_id": "abc123",
  "driver_id": "drv42",
  "PERCLOS": 34.2,
  "perclos_30s": 0.342,
  "ear_thresh_T": 0.205,
  "pitchdown_max_30s": 22.5,
  "yawn_duty_30s": 0.18,
  "confidence": "OK",
  "fps": 27.8,
  ...
}
```

### 3.2 `/v1/state`

Supply the 30‚Äësecond bucket (fields listed under `StateRequest` in `app/models.py`). Example:

```bash
curl -X POST http://localhost:8000/v1/state \
  -H "Content-Type: application/json" \
  -d '{
        "ts_end":"2025-11-08T08:49:16Z",
        "session_id":"abc123",
        "driver_id":"drv42",
        "perclos_30s":0.34,
        "pitchdown_max_30s":27.0,
        "droop_duty_30s":0.32,
        "yawn_duty_30s":0.18,
        "confidence":"OK",
        "fps":26.7
      }'
```

Returns

```
{
  "state": "Drowsy",
  "risk_score": 78,
  "state_confidence": "OK",
  "reasons": [ ... ],
  "thresholds_used": { ... }
}
```

Responses are cached for 2 minutes keyed by `(session_id, driver_id)`, allowing vitals to look up the latest state.

### 3.3 `/v1/sim/hr*`

All three vitals endpoints share the same body:

```
{
  "session_id": "abc123",
  "driver_id": "drv42",
  "state": "Drowsy",   // optional override (defaults to latest cached state)
  "seed": 42            // optional deterministic sampling
}
```

If `state` is omitted you **must** have called `/v1/state` in the last ~2 minutes for that session/driver. Otherwise you‚Äôll receive `400 {"detail":"no recent state for session/driver"}`.

Example response (`/v1/sim/vitals`):

```
{
  "ts": "2025-11-08T09:12:02.418Z",
  "session_id": "abc123",
  "driver_id": "drv42",
  "state_used": "Drowsy",
  "confidence": "OK",
  "hr_bpm": 68.7,
  "hrv_rmssd_ms": 44.2,
  "ranges_used": {
    "hr": {"min":60,"max":75},
    "hrv": {"min":30,"max":60}
  },
  "seed": 42
}
```

Behind the scenes each metric uses truncated normal sampling, inertia (keeps values smooth), oscillation, and optional range widening when the latest state confidence isn‚Äôt ‚ÄúOK‚Äù.

---

## 4. Internal layout

```
app/
‚îú‚îÄ‚îÄ analyzer.py         # MediaPipe/OpenCV processing of 30s windows
‚îú‚îÄ‚îÄ config.py           # Shared thresholds & vitals ranges
‚îú‚îÄ‚îÄ main.py             # FastAPI wiring
‚îú‚îÄ‚îÄ models.py           # Pydantic schemas for every endpoint
‚îú‚îÄ‚îÄ sim_vitals.py       # HR/HRV generation logic
‚îú‚îÄ‚îÄ state_classifier.py # Lucid/Drowsy/Asleep rules + hysteresis cache
‚îú‚îÄ‚îÄ state_store.py      # Keeps latest state per session/driver
‚îú‚îÄ‚îÄ utils.py            # Timestamp parsing, ffprobe helpers
‚îú‚îÄ‚îÄ video.py            # Video window extraction helper
‚îî‚îÄ‚îÄ __init__.py
api_tester.html         # One-page manual tester
requirements.txt        # Runtime + tooling deps
README.md               # This document
```

Each module contains short docstrings explaining its purpose. If you‚Äôre diving into analysis or state logic, start with `analyzer.py` and `state_classifier.py`‚Äîthey map closely to the legacy browser code and the rules described in product docs.

---

## 5. Working with the tester

1. Open `api_tester.html` in your browser.
2. Enter the API base URL (default `http://localhost:8000`).
3. Upload a clip, choose the timestamp you want insights for, and click **Run 30s Analysis**.
4. When the analytics response arrives the tester automatically calls `/v1/state`, shows the reasons, and unlocks the **Driver Vitals** buttons so you can fetch HR/HRV.

Everything shown on the page is the raw JSON returned by the API, so you can copy/paste samples into unit tests or client fixtures.

---

## 6. Development tips

- **Video prep:** downscale clips to 720p/30fps when possible; OpenCV decode time dominates long requests.
- **Reusing work:** `/api/window` always recomputes the 30‚Äësecond window. If you expect repeated queries for the same clip, consider caching window results client-side or adding a persistence layer.
- **State TTLs:** vitals cache entries expire 2 minutes after the state was *recorded*, not the bucket timestamp. If you queue state calls in advance, your vitals requests will stay hot.
- **Seeding vitals:** include `seed` when writing integration tests‚Äîusing the same seed returns the same HR/HRV values, even across restarts.

---

## 7. Testing & linting

```bash
pytest tests/test_state_classifier.py tests/test_sim_vitals.py
```

The classifier tests cover every rule path (Lucid, Drowsy, Asleep, low-confidence). The vitals tests cover deterministic seeding, inertia, range widening, and error handling.

Linting/formatting is not enforced yet; run `ruff`/`black` locally if you prefer a stricter style.

---

## 8. Troubleshooting

| Symptom | Likely cause | Fix |
|---------|--------------|-----|
| `/v1/sim/hr` returns `400 no recent state` | `/v1/state` hasn‚Äôt been called for that session/driver in the last 2 minutes. | Call `/v1/state` after `/api/window`, or provide `state` in the vitals body. |
| `/api/window` takes a long time | High-res or long clip, slow decode, or running on low-power hardware. | Downscale video, trim unnecessary footage, or move API to a beefier machine. |
| Tester stuck on ‚ÄúUploading clip‚Ä¶‚Äù | Browser can‚Äôt reach API (wrong base URL or server down). | Confirm Uvicorn logs show requests, double-check the address/port. |
| Import errors running pytest | Virtualenv not activated. | `source .venv/bin/activate` before running tests. |

---

## 9. Next steps

- Persist 30‚Äësecond window outputs if you need historical audits.
- Replace MediaPipe with an accelerated eye/mouth/head model if GPU support becomes a requirement.
- Add authentication (API keys or mTLS) when deploying beyond local dev.

For any other questions, ping the platform channel or open an issue in this repo. Happy shipping! üööüí§

---

## 10. Snowflake ‚Äî local live test

If you'd like to validate a live Snowflake connection from your local machine, follow these steps. The project provides `scripts/test_snowflake.py` which attempts to connect and print counts from `DRIVERS` and `DROWSINESS_MEASUREMENTS`.

1. Install deps and activate your venv:

```powershell
python -m venv .venv
.venv\Scripts\Activate.ps1
pip install -r requirements.txt
```

2. Set environment variables (PowerShell example):

```powershell
$env:SNOWFLAKE_USER = "FAWAZSABIR"
$env:SNOWFLAKE_PASSWORD = "<your_password>"
$env:SNOWFLAKE_ACCOUNT = "NV61963"
$env:SNOWFLAKE_WAREHOUSE = "COMPUTE_WH"
$env:SNOWFLAKE_DATABASE = "LCD_ENDPOINTS"
$env:SNOWFLAKE_SCHEMA = "PUBLIC"
```

Important: do NOT commit real credentials into the repo. Consider using a local `.env` file (see `.env.example`) with `python-dotenv` for development convenience.

3. Run the test script from the `api2` directory:

```powershell
python scripts/test_snowflake.py
```

The script will print the connected user/account and attempt to count rows in the two tables. If the tables do not exist or permissions are insufficient you'll see an error message explaining the problem.

If you want me to wire automatic persistence of analysis results into Snowflake (for example, insert every analysis window into `DROWSINESS_MEASUREMENTS`), tell me the exact table schema (column names and types) or confirm a minimal column set and I'll add the integration.
